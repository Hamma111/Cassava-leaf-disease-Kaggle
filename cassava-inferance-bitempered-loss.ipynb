{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-02-07T13:42:21.395462Z",
     "iopub.status.busy": "2021-02-07T13:42:21.394708Z",
     "iopub.status.idle": "2021-02-07T13:43:18.348754Z",
     "shell.execute_reply": "2021-02-07T13:43:18.347603Z"
    },
    "papermill": {
     "duration": 56.973521,
     "end_time": "2021-02-07T13:43:18.348870",
     "exception": false,
     "start_time": "2021-02-07T13:42:21.375349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --quiet ../input/kerasapplications/keras-team-keras-applications-3b180cb\n",
    "!pip install --quiet /kaggle/input/efficientnet-git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-07T13:43:18.379742Z",
     "iopub.status.busy": "2021-02-07T13:43:18.378930Z",
     "iopub.status.idle": "2021-02-07T13:43:23.868343Z",
     "shell.execute_reply": "2021-02-07T13:43:23.867558Z"
    },
    "papermill": {
     "duration": 5.508722,
     "end_time": "2021-02-07T13:43:23.868491",
     "exception": false,
     "start_time": "2021-02-07T13:43:18.359769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import cv2\n",
    "import re\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout,\\\n",
    "        Flatten,GlobalAveragePooling2D,BatchNormalization, Activation\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "\n",
    "import efficientnet.keras as efn \n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-02-07T13:43:23.898724Z",
     "iopub.status.busy": "2021-02-07T13:43:23.898102Z",
     "iopub.status.idle": "2021-02-07T13:43:23.906991Z",
     "shell.execute_reply": "2021-02-07T13:43:23.906354Z"
    },
    "papermill": {
     "duration": 0.026183,
     "end_time": "2021-02-07T13:43:23.907115",
     "exception": false,
     "start_time": "2021-02-07T13:43:23.880932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS: 1\n"
     ]
    }
   ],
   "source": [
    "# Detect hardware, return appropriate distribution strategy\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print(f'Running on TPU {tpu.master()}')\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "REPLICAS = strategy.num_replicas_in_sync\n",
    "print(f'REPLICAS: {REPLICAS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-02-07T13:43:23.938357Z",
     "iopub.status.busy": "2021-02-07T13:43:23.937841Z",
     "iopub.status.idle": "2021-02-07T13:43:23.941887Z",
     "shell.execute_reply": "2021-02-07T13:43:23.941424Z"
    },
    "papermill": {
     "duration": 0.021621,
     "end_time": "2021-02-07T13:43:23.941975",
     "exception": false,
     "start_time": "2021-02-07T13:43:23.920354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#setting\n",
    "SEED = 100\n",
    "DEBUG = False\n",
    "WANDB = False\n",
    "# TARGET_SIZE = 512\n",
    "VALIDATION_SIZE = 0.2\n",
    "BATCH_SIZE = 32 *REPLICAS\n",
    "LEARNING_RATE = 3e-5 * REPLICAS\n",
    "EPOCHS=40\n",
    "MODEL_NAME = \"EfficentNetB4\"\n",
    "N_FOLDS = 5\n",
    "\n",
    "TTA = True\n",
    "N_TTA = 4\n",
    "\n",
    "#For BiTempered loss function\n",
    "T_1 = 0.3\n",
    "T_2 = 1.2\n",
    "SMOOTH_FRACTION = 0.01\n",
    "N_ITER = 5\n",
    "\n",
    "HEIGHT = 500\n",
    "WIDTH = 500\n",
    "HEIGHT_RS = 512\n",
    "WIDTH_RS = 512\n",
    "CHANNELS = 3\n",
    "N_CLASSES = 5\n",
    "\n",
    "MODEL_SAVE_PATH = \"\"\n",
    "\n",
    "if DEBUG:\n",
    "    EPOCHS = 2\n",
    "    # LEARNING_RATE = 3e-5 * REPLICAS\n",
    "    # TARGET_SIZE = 512\n",
    "    # BATCH_SIZE = 8*REPLICAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-02-07T13:43:23.997745Z",
     "iopub.status.busy": "2021-02-07T13:43:23.971945Z",
     "iopub.status.idle": "2021-02-07T13:43:24.007204Z",
     "shell.execute_reply": "2021-02-07T13:43:24.006780Z"
    },
    "papermill": {
     "duration": 0.054305,
     "end_time": "2021-02-07T13:43:24.007284",
     "exception": false,
     "start_time": "2021-02-07T13:43:23.952979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data augmentation @cdeotte kernel: https://www.kaggle.com/cdeotte/rotation-augmentation-gpu-tpu-0-96\n",
    "def transform_rotation(image, height, rotation):\n",
    "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
    "    # output - image randomly rotated\n",
    "    DIM = height\n",
    "    XDIM = DIM%2 #fix for size 331\n",
    "    \n",
    "    rotation = rotation * tf.random.uniform([1],dtype='float32')\n",
    "    # CONVERT DEGREES TO RADIANS\n",
    "    rotation = math.pi * rotation / 180.\n",
    "    \n",
    "    # ROTATION MATRIX\n",
    "    c1 = tf.math.cos(rotation)\n",
    "    s1 = tf.math.sin(rotation)\n",
    "    one = tf.constant([1],dtype='float32')\n",
    "    zero = tf.constant([0],dtype='float32')\n",
    "    rotation_matrix = tf.reshape(tf.concat([c1,s1,zero, -s1,c1,zero, zero,zero,one],axis=0),[3,3])\n",
    "\n",
    "    # LIST DESTINATION PIXEL INDICES\n",
    "    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n",
    "    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n",
    "    z = tf.ones([DIM*DIM],dtype='int32')\n",
    "    idx = tf.stack( [x,y,z] )\n",
    "    \n",
    "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
    "    idx2 = K.dot(rotation_matrix,tf.cast(idx,dtype='float32'))\n",
    "    idx2 = K.cast(idx2,dtype='int32')\n",
    "    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n",
    "    \n",
    "    # FIND ORIGIN PIXEL VALUES \n",
    "    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n",
    "    d = tf.gather_nd(image, tf.transpose(idx3))\n",
    "        \n",
    "    return tf.reshape(d,[DIM,DIM,3])\n",
    "\n",
    "def transform_shear(image, height, shear):\n",
    "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
    "    # output - image randomly sheared\n",
    "    DIM = height\n",
    "    XDIM = DIM%2 #fix for size 331\n",
    "    \n",
    "    shear = shear * tf.random.uniform([1],dtype='float32')\n",
    "    shear = math.pi * shear / 180.\n",
    "        \n",
    "    # SHEAR MATRIX\n",
    "    one = tf.constant([1],dtype='float32')\n",
    "    zero = tf.constant([0],dtype='float32')\n",
    "    c2 = tf.math.cos(shear)\n",
    "    s2 = tf.math.sin(shear)\n",
    "    shear_matrix = tf.reshape(tf.concat([one,s2,zero, zero,c2,zero, zero,zero,one],axis=0),[3,3])    \n",
    "\n",
    "    # LIST DESTINATION PIXEL INDICES\n",
    "    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n",
    "    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n",
    "    z = tf.ones([DIM*DIM],dtype='int32')\n",
    "    idx = tf.stack( [x,y,z] )\n",
    "    \n",
    "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
    "    idx2 = K.dot(shear_matrix,tf.cast(idx,dtype='float32'))\n",
    "    idx2 = K.cast(idx2,dtype='int32')\n",
    "    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n",
    "    \n",
    "    # FIND ORIGIN PIXEL VALUES \n",
    "    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n",
    "    d = tf.gather_nd(image, tf.transpose(idx3))\n",
    "        \n",
    "    return tf.reshape(d,[DIM,DIM,3])\n",
    "\n",
    "# CutOut\n",
    "def data_augment_cutout(image, min_mask_size=(int(HEIGHT * .1), int(HEIGHT * .1)), \n",
    "                        max_mask_size=(int(HEIGHT * .125), int(HEIGHT * .125))):\n",
    "    p_cutout = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    \n",
    "    if p_cutout > .85: # 10~15 cut outs\n",
    "        n_cutout = tf.random.uniform([], 10, 15, dtype=tf.int32)\n",
    "        image = random_cutout(image, HEIGHT, WIDTH, \n",
    "                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=n_cutout)\n",
    "    elif p_cutout > .6: # 5~10 cut outs\n",
    "        n_cutout = tf.random.uniform([], 5, 10, dtype=tf.int32)\n",
    "        image = random_cutout(image, HEIGHT, WIDTH, \n",
    "                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=n_cutout)\n",
    "    elif p_cutout > .25: # 2~5 cut outs\n",
    "        n_cutout = tf.random.uniform([], 2, 5, dtype=tf.int32)\n",
    "        image = random_cutout(image, HEIGHT, WIDTH, \n",
    "                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=n_cutout)\n",
    "    else: # 1 cut out\n",
    "        image = random_cutout(image, HEIGHT, WIDTH, \n",
    "                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=1)\n",
    "\n",
    "    return image\n",
    "\n",
    "def random_cutout(image, height, width, channels=3, min_mask_size=(10, 10), max_mask_size=(80, 80), k=1):\n",
    "    assert height > min_mask_size[0]\n",
    "    assert width > min_mask_size[1]\n",
    "    assert height > max_mask_size[0]\n",
    "    assert width > max_mask_size[1]\n",
    "\n",
    "    for i in range(k):\n",
    "      mask_height = tf.random.uniform(shape=[], minval=min_mask_size[0], maxval=max_mask_size[0], dtype=tf.int32)\n",
    "      mask_width = tf.random.uniform(shape=[], minval=min_mask_size[1], maxval=max_mask_size[1], dtype=tf.int32)\n",
    "\n",
    "      pad_h = height - mask_height\n",
    "      pad_top = tf.random.uniform(shape=[], minval=0, maxval=pad_h, dtype=tf.int32)\n",
    "      pad_bottom = pad_h - pad_top\n",
    "\n",
    "      pad_w = width - mask_width\n",
    "      pad_left = tf.random.uniform(shape=[], minval=0, maxval=pad_w, dtype=tf.int32)\n",
    "      pad_right = pad_w - pad_left\n",
    "\n",
    "      cutout_area = tf.zeros(shape=[mask_height, mask_width, channels], dtype=tf.uint8)\n",
    "\n",
    "      cutout_mask = tf.pad([cutout_area], [[0,0],[pad_top, pad_bottom], [pad_left, pad_right], [0,0]], constant_values=1)\n",
    "      cutout_mask = tf.squeeze(cutout_mask, axis=0)\n",
    "      image = tf.multiply(tf.cast(image, tf.float32), tf.cast(cutout_mask, tf.float32))\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-02-07T13:43:24.044580Z",
     "iopub.status.busy": "2021-02-07T13:43:24.043204Z",
     "iopub.status.idle": "2021-02-07T13:43:24.046077Z",
     "shell.execute_reply": "2021-02-07T13:43:24.045672Z"
    },
    "papermill": {
     "duration": 0.027893,
     "end_time": "2021-02-07T13:43:24.046160",
     "exception": false,
     "start_time": "2021-02-07T13:43:24.018267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_augment(image, label):\n",
    "    p_rotation = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_shear = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_cutout = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    flip_left = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    flip_right = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    \n",
    "#     # Shear\n",
    "#     if p_shear > .2:\n",
    "#         if p_shear > .6:\n",
    "#             image = transform_shear(image, HEIGHT, shear=20.)\n",
    "#         else:\n",
    "#             image = transform_shear(image, HEIGHT, shear=-20.)\n",
    "            \n",
    "    # Rotation\n",
    "    if p_rotation > .2:\n",
    "        if p_rotation > .6:\n",
    "            image = transform_rotation(image, HEIGHT, rotation=10.)\n",
    "        else:\n",
    "            image = transform_rotation(image, HEIGHT, rotation=-10.)\n",
    "            \n",
    "    # Flips\n",
    "    if flip_left>0.5:\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "    if flip_right>0.5 :\n",
    "        image = tf.image.random_flip_up_down(image)\n",
    "#     if p_spatial > .75:\n",
    "#         image = tf.image.transpose(image)\n",
    "        \n",
    "#     # Rotates\n",
    "#     if p_rotate > .75:\n",
    "#         image = tf.image.rot90(image, k=3) # rotate 270º\n",
    "#     elif p_rotate > .5:\n",
    "#         image = tf.image.rot90(image, k=2) # rotate 180º\n",
    "#     elif p_rotate > .25:\n",
    "#         image = tf.image.rot90(image, k=1) # rotate 90º\n",
    "        \n",
    "#     # Pixel-level transforms\n",
    "#     if p_pixel_1 >= .4:\n",
    "#         image = tf.image.random_saturation(image, lower=.7, upper=1.3)\n",
    "#     if p_pixel_2 >= .4:\n",
    "#         image = tf.image.random_contrast(image, lower=.8, upper=1.2)\n",
    "#     if p_pixel_3 >= .4:\n",
    "#         image = tf.image.random_brightness(image, max_delta=.1)\n",
    "        \n",
    "#     # Crops\n",
    "#     if p_crop > .6:\n",
    "#         if p_crop > .9:\n",
    "#             image = tf.image.central_crop(image, central_fraction=.5)\n",
    "#         elif p_crop > .8:\n",
    "#             image = tf.image.central_crop(image, central_fraction=.6)\n",
    "#         elif p_crop > .7:\n",
    "#             image = tf.image.central_crop(image, central_fraction=.7)\n",
    "#         else:\n",
    "#             image = tf.image.central_crop(image, central_fraction=.8)\n",
    "#     elif p_crop > .3:\n",
    "#         crop_size = tf.random.uniform([], int(HEIGHT*.6), HEIGHT, dtype=tf.int32)\n",
    "#         image = tf.image.random_crop(image, size=[crop_size, crop_size, CHANNELS])\n",
    "            \n",
    "    image = tf.image.resize(image, size=[HEIGHT, WIDTH])\n",
    "\n",
    "#     if p_cutout > .5:\n",
    "#         image = data_augment_cutout(image)\n",
    "        \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-02-07T13:43:24.088310Z",
     "iopub.status.busy": "2021-02-07T13:43:24.081535Z",
     "iopub.status.idle": "2021-02-07T13:43:24.090921Z",
     "shell.execute_reply": "2021-02-07T13:43:24.090489Z"
    },
    "papermill": {
     "duration": 0.033525,
     "end_time": "2021-02-07T13:43:24.091007",
     "exception": false,
     "start_time": "2021-02-07T13:43:24.057482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def center_crop(image):\n",
    "#     image = tf.reshape(image, [600, 800, CHANNELS]) # Original shape\n",
    "    image = tf.image.resize(image, [600, 800])\n",
    "    \n",
    "    h, w = image.shape[0], image.shape[1]\n",
    "    if h > w:\n",
    "        image = tf.image.crop_to_bounding_box(image, (h - w) // 2, 0, w, w)\n",
    "    else:\n",
    "        image = tf.image.crop_to_bounding_box(image, 0, (w - h) // 2, h, h)\n",
    "        \n",
    "#     image = tf.image.resize(image, [HEIGHT, WIDTH]) # Expected shape\n",
    "    return image\n",
    "\n",
    "# Datasets utility functions\n",
    "def decode_image(image_data):\n",
    "    \"\"\"\n",
    "        1. Decode a JPEG-encoded image to a uint8 tensor.\n",
    "        2. Cast tensor to float and normalizes (range between 0 and 1).\n",
    "        3. Resize and reshape images to the expected size.\n",
    "    \"\"\"\n",
    "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
    "    \n",
    "    image = tf.cast(image, tf.float32)/255.0\n",
    "    \n",
    "#     image = center_crop(image)\n",
    "    \n",
    "    \n",
    "   \n",
    "                      \n",
    "    image = tf.image.resize(image, [HEIGHT, WIDTH])\n",
    "    image = tf.reshape(image, [HEIGHT, WIDTH, 3])\n",
    "    return image\n",
    "\n",
    "def read_tfrecord(example, labeled=True):\n",
    "    \"\"\"\n",
    "        1. Parse data based on the 'TFREC_FORMAT' map.\n",
    "        2. Decode image.\n",
    "        3. If 'labeled' returns (image, label) if not (image, name).\n",
    "    \"\"\"\n",
    "    if labeled:\n",
    "        TFREC_FORMAT = {\n",
    "            'image': tf.io.FixedLenFeature([], tf.string), \n",
    "            'target': tf.io.FixedLenFeature([], tf.int64), \n",
    "        }\n",
    "    else:\n",
    "        TFREC_FORMAT = {\n",
    "            'image': tf.io.FixedLenFeature([], tf.string), \n",
    "            'image_name': tf.io.FixedLenFeature([], tf.string), \n",
    "        }\n",
    "    example = tf.io.parse_single_example(example, TFREC_FORMAT)\n",
    "    image = decode_image(example['image'])\n",
    "   \n",
    "    if labeled:\n",
    "        label_or_name = tf.cast(example['target'], tf.int32)\n",
    "    else:\n",
    "        label_or_name =  example['image_name']\n",
    "    return image, label_or_name\n",
    "\n",
    "def load_dataset(filenames, labeled=True, ordered=False):\n",
    "    \"\"\"\n",
    "        Create a Tensorflow dataset from TFRecords.\n",
    "    \"\"\"\n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        ignore_order.experimental_deterministic = False\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n",
    "    dataset = dataset.with_options(ignore_order)\n",
    "    dataset = dataset.map(lambda x: read_tfrecord(x, labeled=labeled), num_parallel_calls=AUTO)\n",
    "    return dataset\n",
    "\n",
    "def get_dataset(FILENAMES, labeled=True, ordered=False, repeated=False, augment=False):\n",
    "    \"\"\"\n",
    "        Return a Tensorflow dataset ready for training or inference.\n",
    "    \"\"\"\n",
    "    dataset = load_dataset(FILENAMES, labeled=labeled, ordered=ordered)\n",
    "    if augment:\n",
    "        dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n",
    "    if repeated:\n",
    "        dataset = dataset.repeat()\n",
    "    if not ordered:\n",
    "        dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-02-07T13:43:24.117354Z",
     "iopub.status.busy": "2021-02-07T13:43:24.116859Z",
     "iopub.status.idle": "2021-02-07T13:43:24.127234Z",
     "shell.execute_reply": "2021-02-07T13:43:24.126542Z"
    },
    "papermill": {
     "duration": 0.025024,
     "end_time": "2021-02-07T13:43:24.127323",
     "exception": false,
     "start_time": "2021-02-07T13:43:24.102299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import module we'll need to import our custom module\n",
    "from shutil import copyfile\n",
    "\n",
    "# copy our file into the working directory (make sure it has .py suffix)\n",
    "copyfile(src = \"../input/bitempered-logistic-loss-tensorflow-v2/bi_tempered_loss.py\", dst = \"../working/loss.py\")\n",
    "\n",
    "# import all our functions\n",
    "from loss import bi_tempered_logistic_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-02-07T13:43:24.157549Z",
     "iopub.status.busy": "2021-02-07T13:43:24.157030Z",
     "iopub.status.idle": "2021-02-07T13:43:24.160637Z",
     "shell.execute_reply": "2021-02-07T13:43:24.160163Z"
    },
    "papermill": {
     "duration": 0.021496,
     "end_time": "2021-02-07T13:43:24.160731",
     "exception": false,
     "start_time": "2021-02-07T13:43:24.139235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "  class BiTemperedLogisticLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, t1, t2, lbl_smth, n_iter):\n",
    "      super(BiTemperedLogisticLoss, self).__init__()\n",
    "      self.t1 = t1\n",
    "      self.t2 = t2\n",
    "      self.lbl_smth = lbl_smth\n",
    "      self.n_iter = n_iter\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "      return bi_tempered_logistic_loss(y_pred, y_true, self.t1, self.t2, self.lbl_smth, self.n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-07T13:43:24.194026Z",
     "iopub.status.busy": "2021-02-07T13:43:24.193455Z",
     "iopub.status.idle": "2021-02-07T13:44:34.246996Z",
     "shell.execute_reply": "2021-02-07T13:44:34.246003Z"
    },
    "papermill": {
     "duration": 70.074474,
     "end_time": "2021-02-07T13:44:34.247108",
     "exception": false,
     "start_time": "2021-02-07T13:43:24.172634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  seresnext50_fold0_best.h5\n",
      "TTA step: 1/4\n",
      "TTA step: 2/4\n",
      "TTA step: 3/4\n",
      "TTA step: 4/4\n",
      "Model:  seresnext50_fold1_best.h5\n",
      "TTA step: 1/4\n",
      "TTA step: 2/4\n",
      "TTA step: 3/4\n",
      "TTA step: 4/4\n",
      "Model:  seresnext50_fold2_best.h5\n",
      "TTA step: 1/4\n",
      "TTA step: 2/4\n",
      "TTA step: 3/4\n",
      "TTA step: 4/4\n",
      "Model:  seresnext50_fold3_best.h5\n",
      "TTA step: 1/4\n",
      "TTA step: 2/4\n",
      "TTA step: 3/4\n",
      "TTA step: 4/4\n"
     ]
    }
   ],
   "source": [
    "# GCS_PATH= KaggleDatasets().get_gcs_path('cassava-leaf-disease-classification')+'/test_tfrecords' \n",
    "files_path = '../input/cassava-leaf-disease-classification/test_images'\n",
    "\n",
    "TEST_FILENAMES = tf.io.gfile.glob('../input/cassava-leaf-disease-classification/test_tfrecords/*')\n",
    "# print(TEST_FILENAMES)\n",
    "model_base_path = '../input/cas-inference/'\n",
    "\n",
    "model_path_list = os.listdir(model_base_path)\n",
    "# print(model_path_list)\n",
    "\n",
    "# model_path_list = [x for x in model_path_list if x.startswith('EfficentNet4_best_btl_') ]\n",
    "\n",
    "model_path_list = [ \n",
    "    'seresnext50_fold0_best.h5',\n",
    "    'seresnext50_fold1_best.h5',\n",
    "    'seresnext50_fold2_best.h5',\n",
    "    'seresnext50_fold3_best.h5',\n",
    "#     'seresnext50_fold0_best.h5',\n",
    "#     'seresnext50_fold1_best.h5',\n",
    "#     'seresnext50_fold2_best.h5',\n",
    "#     'seresnext50_fold3_last.h5',\n",
    "]\n",
    "\n",
    "test_preds = np.zeros((len(os.listdir(files_path)), N_CLASSES))\n",
    "\n",
    "for model_path in model_path_list:\n",
    "    print(\"Model: \", model_path)\n",
    "    tf.keras.backend.clear_session()\n",
    "#     print(os.path.join(model_base_path,model_path))\n",
    "    model = tf.keras.models.load_model(os.path.join(model_base_path,model_path) )\n",
    "#                                       custom_objects={'loss': BiTemperedLogisticLoss(t1=T_1, t2=T_2, lbl_smth=SMOOTH_FRACTION, n_iter=N_ITER)},\n",
    "#                                        compile=False)\n",
    "    \n",
    "    if TTA:\n",
    "        \n",
    "        for step in range(N_TTA):\n",
    "            print(f\"TTA step: {step+1}/{N_TTA}\")\n",
    "            test_ds = get_dataset(TEST_FILENAMES, labeled=False, ordered=True, augment = True)\n",
    "            x_test = test_ds.map(lambda image, image_name: image)\n",
    "            test_preds += model.predict(x_test)/len(model_path_list)\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        test_ds = get_dataset(TEST_FILENAMES, labeled=False, ordered=True)\n",
    "        x_test = test_ds.map(lambda image, image_name: image)\n",
    "        test_preds += model.predict(x_test)/len(model_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-07T13:44:34.291188Z",
     "iopub.status.busy": "2021-02-07T13:44:34.290380Z",
     "iopub.status.idle": "2021-02-07T13:44:34.639436Z",
     "shell.execute_reply": "2021-02-07T13:44:34.638957Z"
    },
    "papermill": {
     "duration": 0.374078,
     "end_time": "2021-02-07T13:44:34.639543",
     "exception": false,
     "start_time": "2021-02-07T13:44:34.265465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2216849948.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label\n",
       "0  2216849948.jpg      4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_preds = np.argmax(test_preds, axis=-1)\n",
    "image_names = [img_name.numpy().decode('utf-8') for img, img_name in iter(test_ds.unbatch())]\n",
    "\n",
    "submission = pd.DataFrame({'image_id': image_names, 'label': test_preds})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "display(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-07T13:44:34.680329Z",
     "iopub.status.busy": "2021-02-07T13:44:34.679540Z",
     "iopub.status.idle": "2021-02-07T13:45:01.176501Z",
     "shell.execute_reply": "2021-02-07T13:45:01.174886Z"
    },
    "papermill": {
     "duration": 26.519011,
     "end_time": "2021-02-07T13:45:01.176683",
     "exception": false,
     "start_time": "2021-02-07T13:44:34.657672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: efficientnet in /opt/conda/lib/python3.7/site-packages (1.1.1)\r\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.7/site-packages (from efficientnet) (0.16.2)\r\n",
      "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /opt/conda/lib/python3.7/site-packages (from efficientnet) (1.0.8)\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.18.5)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (2.10.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.14.0)\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.18.5)\r\n",
      "Requirement already satisfied: scipy>=0.19.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (1.4.1)\r\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (3.2.1)\r\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (2.4)\r\n",
      "Requirement already satisfied: pillow>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (8.0.1)\r\n",
      "Requirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (2.8.0)\r\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (1.1.1)\r\n",
      "Requirement already satisfied: pillow>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (8.0.1)\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.18.5)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.2.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.8.1)\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.18.5)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (0.10.0)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.4.7)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.14.0)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image->efficientnet) (4.4.2)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.14.0)\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.18.5)\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.18.5)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.036363,
     "end_time": "2021-02-07T13:45:01.252108",
     "exception": false,
     "start_time": "2021-02-07T13:45:01.215745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-07T13:45:01.327900Z",
     "iopub.status.busy": "2021-02-07T13:45:01.326865Z",
     "iopub.status.idle": "2021-02-07T13:45:01.329453Z",
     "shell.execute_reply": "2021-02-07T13:45:01.328628Z"
    },
    "papermill": {
     "duration": 0.043264,
     "end_time": "2021-02-07T13:45:01.329583",
     "exception": false,
     "start_time": "2021-02-07T13:45:01.286319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from matplotlib import image as img\n",
    "# from keras import models\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-07T13:45:01.404196Z",
     "iopub.status.busy": "2021-02-07T13:45:01.403349Z",
     "iopub.status.idle": "2021-02-07T13:45:01.405741Z",
     "shell.execute_reply": "2021-02-07T13:45:01.405068Z"
    },
    "papermill": {
     "duration": 0.041935,
     "end_time": "2021-02-07T13:45:01.405877",
     "exception": false,
     "start_time": "2021-02-07T13:45:01.363942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tf.keras.models.load_model('../input/cassava-inference/EfficentNetB4_best_fold_0_.h5',\n",
    "#                                       custom_objects={'loss': BiTemperedLogisticLoss(t1=T_1, t2=T_2, lbl_smth=SMOOTH_FRACTION, n_iter=N_ITER)},\n",
    "#                                        compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-07T13:45:01.478546Z",
     "iopub.status.busy": "2021-02-07T13:45:01.477658Z",
     "iopub.status.idle": "2021-02-07T13:45:01.480182Z",
     "shell.execute_reply": "2021-02-07T13:45:01.479398Z"
    },
    "papermill": {
     "duration": 0.041492,
     "end_time": "2021-02-07T13:45:01.480312",
     "exception": false,
     "start_time": "2021-02-07T13:45:01.438820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model1 = models.load_model('../input/cassava-inference/EfficentNetB4_best_fold_0_.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.031501,
     "end_time": "2021-02-07T13:45:01.542771",
     "exception": false,
     "start_time": "2021-02-07T13:45:01.511270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 165.758282,
   "end_time": "2021-02-07T13:45:03.232125",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-02-07T13:42:17.473843",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
